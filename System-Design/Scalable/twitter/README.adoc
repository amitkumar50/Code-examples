:toc:
:toclevels: 7

  
== Twitter?
Social networking site, where people can post short messages(called tweets 150 characters), follow other people etc. This is read heavy system.

=== 1. Requirements
==== Functional
* Register on system
* post tweet(text, photos, video)
* view timeline: User can view his own
* search tweet: user can search any tweet
* Add himself as follower

==== Non-Functional 
* Scalable
* Reliable

==== Extended
* Retweet, reply

=== 2. API Design (API for every requirement)
[[register]]
register (user_created_userid, system_generated_user_uuid(user_id), name, email, current_timestamp, location)
```
POST https://lb_fqdn:port/v1/register?user_id=12312asa1&name=amit&photo_url=https://photo.com/photo1.png&current_time_stamp=
```

[[posttweet]]
posttweet (user_id, tweet_content(txt,video,photo), content_url, current_timestamp)
```
POST https://lb_fqdn:port/v1/posttweet?user_id=12312asa1&tweet_content(txt,video,photo)=...&content_url=...&current_timestamp=...
```

[[viewtimeline]]
viewtimeline (user_id, current_time)
```
GET  https://lb_fqdn:port/v1/viewtimeline?user_id=12312asa1&current_time=..
```

[[searchTweeet]]
searchTweeet (user_id, tweet_id)
```
GET  https://lb_fqdn:port/v1/searchTweeet?user_id=12312asa1&tweet_id=..
```

[[addFollower]]
addFollower (user_id, followee_user_id)
```
PUT  https://lb_fqdn:port/v1/addFollower?user_id=12312asa1&followee_user_id=..
```

[[boe]]
=== 3. BOE Calculation
* *Ask Interviewer: How many DAU?* DAU = 100M

==== QPS(Queries/sec)
```
DAU = 100M. Active/sec = 100M/86400 = 1000/sec
```

==== Storage Estimates
* *Ask Interviewer: How post tweet(writes)?* 10% of DAU = 10M
```
1 tweet size = 8k(header)+1M(payload) =~ 1MB
1 day storage needed:   10M x 1M = 10TB/day. 
5 years storage neede:  10TB x (365x5 ~ 2000) = 20PB
```

==== Bandwidth Estimate (bytes coming into system/sec)
10TB/day. 10TB/86400 = 100MB/sec

[[db]]
=== 4. DB Schema (What are entities in system)
==== Tables
* user (user_id, email, phone_no, profile_image_url)
* connection_table (user_id, connection_info, timestamp)
* tweets (user_id, tweet_id, tweet_txt_url, tweet_photo_url, tweet_video_url, no_of_likes, no_of_shares, category, timestamp)
* follower_table (user_id_followee, user_id_follower)  //Each row contains information who follows whom

=== 5. HLD
* *1-6.* Same as link:/System-Design/Scalable/facebook/News%20Feed[Facebook news feed]

image::Twitter.jpg?raw=true[Design]

==== <<register, Req-1 Register User>>
* User Client will hit <<register, register REST endpoint>> and server store user data in link:/System-Design/Concepts/Databases/README.adoc#sqlrelationalstructured-vs-nosqlnonrelationalunstructured[postgres-sql](user table, connection table), photo in link:/System-Design/Concepts/Databases/README.adoc#object-vs-block-vs-file-storage[Object Store]
```
User ---data---> (REST)Application_server  -----------> (user_table) Postgres DB 
                            |---profile_photo---> Object Store (amazon S3)
     <--ACK----
```

==== <<posttweet, Req-2 Post Tweet>>
* User Client will hit <<posttweet, posttweet REST endpoint>> with data
* Application server will add entry to <<db, tweets table>>. Store link:/System-Design/Concepts/Databases/README.adoc#object-vs-block-vs-file-storage[photo, video on Object Store]
* ACK sender by getting connection info from <<db, connection table>>.
```c
User ---postweet(data)---> (REST)Application_server  -----------> (tweet_table) Postgres DB 
                                        |---profile_photo---> Object Store (amazon S3)
     <--ACK------------------------
```

==== <<viewtimeline, Req-3 View Timeline>>
* User Client will hit <<viewtimeline, viewtimeline REST endpoint>>.
* Application server will:
** 1. Find all followees of user using <<db, follower table>>
** 2. Will go to <<db, tweets_table>> and find all tweets of all followees
** 3. Order them in sorted by time and return
```c
User ---viewtimeline---> (REST)Application_server                   Followee_table
                                          --1. Find all followees of user-->
                                          <-- <usr1, usr2..> --

                                                                            Tweets_table
                                          -- 2. Find all tweets of followees --> 
                                          <-- <tweet1, tweet2..> --
                            Sort tweets by time
  <------ timeline--------------

SELECT tweets.*, users.* FROM tweets
 JOIN users ON tweets.sender_id = users.id
 JOIN follows ON follows.followee_id = users.id
 WHERE follows.follower_id = current_user
```
====== Problems: Huge Data to Fanout + Timeline creation at runtime
* **Ask Interviewer?** How many people user should be following? Ans:1000
* We know <<boe, DAU=100M. Req/sec=100M/86400=1000. On Peak=3000 timeline read req/sec>>. 
** Every user will see his timeline. Hence timeline requests = 3000/sec.
* <<boe, 1 tweet size=~ 1MB>>. 1 followee does 1 tweet. 1MB x 1000 = 1GB/user request
* Fanout data = 1GB x 3000 = 3TB/sec

======= Solution: Calculate timeline before time

* Suppose usr=amit follows usr=mike.
* Calculate timeline of usr=amit ahead of time and store in link:/System-Design/Concepts/Cache[Cache]
* When usr=mike posts a tweet, add mike's tweet to pre-calculated timeline of usr=amit.


#### Storing Tweets(text,photos,videos)
can be stored on [Shard-DB](/System-Design/Concepts/Databases/Database_Scaling) based on userId, TweetId. But all approaches has issues
  - *a.* As mentioned in [Shard-DB Disadv point-a](/System-Design/Concepts/Databases/Database_Scaling).
  - *b.* if we shard by userId and try generating timeline. App server need to visit every shard and will create latency.
    - We can create tweetID = timestamp+tweetid = xxx 0001
- **[Replication](/System-Design/Concepts/Databases/Database_Scaling):** Master slave
#### Cache 
Application servers, before hitting database, can quickly check if the cache has desired tweets. Memcache
  - [Where Cache can be placed?](/System-Design/Concepts/Cache) 
  - [Cache Eviction LRU](/DS_Questions/Questions/Random/LRUCache)
  - Cache Storage policy (80-20 rule): 20% of users will generate mostly used tweets, we need to store these tweets only in cache.

<a name=lb></a>
## 6. Load Balancers
  - [Where Load Balancer can be placed?](/System-Design/Concepts/Load_Balancer)
1. Between client and application servers
2. Between application servers & DB
3. Between Aggregation servers & cache servers.

<a name=to></a>
## 7. [Overall Tradeoffs/Bottlenecks & correction](/System-Design/Concepts/Bottlenecks_of_Distributed_Systems/Bottlenecks.md)
- *1.* If high number of clients are connected system may respond slow.
  - *Solution:*
    - Provide MOM between Application server & clients which will queue client requests.
    - Provide MOM between synchronization server & clients. MOM can queue millions of requests.
- *2.* Sharding based on Hash of tweetid/userid can fail on overloaded environment.
  - Solutions: 
    - Consistent hashing
    - Monitoring the load using [Artificial Intelligence](https://sites.google.com/site/amitinterviewpreparation/machine-learning) based models, New tweets per day/second, what is the daily peak, Timeline delivery stats, how many tweets per day/second our service is delivering, Average latency that is seen by the user to refresh timeline.
  - *3.* Efficient timeline generation system
    - *Solution:* fb news feed timeline generation
  - *4.* Effective tweet ranking solution?
  - *5.* Suggestion to user for Whom to follow? 
    - This feature will improve user engagement. We can suggest friends of people someone follows, Famous people for the suggestions, people having more followers. As only a few suggestions can be made at any time, use Machine Learning (ML) to shuffle and re-prioritize
  - *6.* How to show top news? 
    - Use crawler to search (news, support, financial, entertainment, etc.) use [ML â€“ supervised learning or Clustering](https://sites.google.com/site/amitinterviewpreparation/machine-learning).

## 
