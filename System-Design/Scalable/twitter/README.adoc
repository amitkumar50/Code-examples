:toc:
:toclevels: 7

  
== Twitter?
Social networking site, where people can post short messages(called tweets 150 characters), follow other people etc. This is read heavy system.

== 1. Requirements
=== Functional
* Register on system
* post tweet(text, photos, video)
* view timeline: User can view his own
* search tweet: user can search any tweet
* Add himself as follower

=== Non-Functional 
* Scalable
* Reliable

=== Extended
* Retweet, reply

== 2. API Design (API for every requirement)
[[register]]
register (user_created_userid, system_generated_user_uuid(user_id), name, email, current_timestamp, location)
```
POST https://lb_fqdn:port/v1/register?user_id=12312asa1&name=amit&photo_url=https://photo.com/photo1.png&current_time_stamp=
```

[[posttweet]]
posttweet (user_id, tweet_content(txt,video,photo), content_url, current_timestamp)
```
POST https://lb_fqdn:port/v1/posttweet?user_id=12312asa1&tweet_content(txt,video,photo)=...&content_url=...&current_timestamp=...
```

[[viewtimeline]]
viewtimeline (user_id, current_time)
```
GET  https://lb_fqdn:port/v1/viewtimeline?user_id=12312asa1&current_time=..
```

[[searchTweeet]]
searchTweeet (user_id, tweet_id)
```
GET  https://lb_fqdn:port/v1/searchTweeet?user_id=12312asa1&tweet_id=..
```

[[addFollower]]
addFollower (user_id, followee_user_id)
```
PUT  https://lb_fqdn:port/v1/addFollower?user_id=12312asa1&followee_user_id=..
```

[[boe]]
== 3. BOE Calculation
* *Ask Interviewer: How many DAU?* DAU = 100M

=== QPS(Queries/sec)
```
DAU = 100M. Active/sec = 100M/86400 = 1000/sec
```

[[storage_estimates]]
=== Storage Estimates (Writes/sec)
* *Ask Interviewer: How many tweet(writes)?* 10% of DAU = 10M/day. 100 tweets/sec
```
1 tweet size = 8k(header)+1M(payload) =~ 1MB
1 day storage needed:   10M x 1M = 10TB/day. 
5 years storage neede:  10TB x (365x5 ~ 2000) = 20PB
```

=== Bandwidth Estimate (bytes coming into system/sec)
10TB/day. 10TB/86400 = 100MB/sec

[[reads_per_sec]]
=== Timeline Reads/sec. Outgoing Tweets/sec. Outgoing data/sec
* **Ask Interviewer Followers/user?** All users will not have same number of followers. 
** 0.1% have 1M Followers=0.1% x 100M = 1M users have 1M followers. 10% have 1000-10k followers(Let's ignore these).
** 1 user having 1M follower tweets. System has to make 1M timeline writes
** <storage_estimates, Writess/sec=100>> 1M x 100 = 1T/sec timeline writes/sec. 1T x 1MB(tweet size) = 1PB/sec

[[db]]
== 4. DB Schema (What are entities in system)
=== Tables
* user (user_id, email, phone_no, profile_image_url)
* connection_table (user_id, connection_info, timestamp)
* tweets (user_id, tweet_id, tweet_txt_url, tweet_photo_url, tweet_video_url, no_of_likes, no_of_shares, category, timestamp)
* follower_table (user_id_followee, user_id_follower)  //Each row contains information who follows whom

== 5. HLD
* *1-6.* Same as link:/System-Design/Scalable/facebook/News%20Feed[Facebook news feed]

image::Twitter.jpg?raw=true[Design]

=== <<register, Req-1 Register User>>
* User Client will hit <<register, register REST endpoint>> and server store user data in link:/System-Design/Concepts/Databases/README.adoc#sqlrelationalstructured-vs-nosqlnonrelationalunstructured[postgres-sql](user table, connection table), photo in link:/System-Design/Concepts/Databases/README.adoc#object-vs-block-vs-file-storage[Object Store]
```
User ---data---> (REST)Application_server  -----------> (user_table) Postgres DB 
                            |---profile_photo---> Object Store (amazon S3)
     <--ACK----
```

=== <<posttweet, Req-2 Post Tweet>>
* User Client will hit <<posttweet, posttweet REST endpoint>> with data
* Application server will add entry to <<db, tweets table>>. Store link:/System-Design/Concepts/Databases/README.adoc#object-vs-block-vs-file-storage[photo, video on Object Store]
* ACK sender by getting connection info from <<db, connection table>>.
```c
User ---postweet(data)---> (REST)Application_server  -----------> (tweet_table) Postgres DB 
                                        |---profile_photo---> Object Store (amazon S3)
     <--ACK------------------------
```

=== <<viewtimeline, Req-3 View Timeline>>
* User Client will hit <<viewtimeline, viewtimeline REST endpoint>>.
* Application server will:
** 1. Find all followees of user using <<db, follower table>>
** 2. Will go to <<db, tweets_table>> and find all tweets of all followees
** 3. Order them in sorted by time and return
```c
User ---viewtimeline---> (REST)Application_server                   Followee_table
                                          --1. Find all followees of user-->
                                          <-- <usr1, usr2..> --

                                                                            Tweets_table
                                          -- 2. Find all tweets of followees --> 
                                          <-- <tweet1, tweet2..> --
                            Sort tweets by time
  <------ timeline--------------

SELECT tweets.*, users.* FROM tweets
 JOIN users ON tweets.sender_id = users.id
 JOIN follows ON follows.followee_id = users.id
 WHERE follows.follower_id = current_user
```
==== Problems: Huge Data to Fanout + Timeline creation at runtime
* <<reads_per_sec, Outgoing bytes/sec = 1PB/sec>>

===== Sol-1: Calculate timeline of user before time and store in Cache
* Suppose usr=amit follows usr=mike.
* Calculate timeline of usr=amit ahead of time and store in link:/System-Design/Concepts/Cache/README.adoc[Cache=Redis or memcached].
* When usr=mike posts a tweet, add mike's tweet to pre-calculated timeline of usr=amit.
* But at this scale=1Petabyte/sec outflow data Cache will not work

===== Sol-2: Calculate timeline of user before time and store in Big data Storage 
a. Storage like(eg: link:/System-Design/Concepts/Databases/NOSQL/Wide_Coloumn/README.adoc#1-apache-hbase[Apache HBase], Apache Cassandra, or link:System-Design/Concepts/AWS/Storage/Object_Store/S3.adoc[Amazon S3] or GCP) which can store and scale to Petabytes
b. link:/System-Design/Concepts/Databases/Database_Scaling/Sharding/README.adoc[Data Sharding]
c. Cache hotdata set using link:/System-Design/Concepts/Cache/README.adoc[Redis or memcached]

=== <<searchTweeet, Req-4 Search Tweet>>
word to tweet mapping is stored as link:/System-Design/Concepts/Databases/Indexing[reverse indexing]
```c
client -----> Load_balancer -------> Application_Server
                search tweet(word=xyz)
                                              --------SELECT * from tweets_table
                                                      where title contains=xyz--->  Tweets_table
                                    Arrange with time
  <--------------------------------

```

=== <<addFollower, Req-5 Add self as follower>>
```c
client ---------> Load_balancer -----------> Application_Server
        PUT user_id=11&followee_user_id=xy   REST API(add_follower)
                                              --------INSERT_INTO follower_table
                                                      where followee=xy --->  Follower_table
  <----------------ACK-----------------------
```

=== link:/System-Design/Concepts/Bottlenecks_of_Distributed_Systems/Bottlenecks.md[Overall Tradeoffs/Bottlenecks & correction]
- *1.* If high number of clients are connected system may respond slow.
  - *Solution:*
    - Provide MOM between Application server & clients which will queue client requests.
    - Provide MOM between synchronization server & clients. MOM can queue millions of requests.
- *2.* Sharding based on Hash of tweetid/userid can fail on overloaded environment.
  - Solutions: 
    - Consistent hashing
    - Monitoring the load using [Artificial Intelligence](https://sites.google.com/site/amitinterviewpreparation/machine-learning) based models, New tweets per day/second, what is the daily peak, Timeline delivery stats, how many tweets per day/second our service is delivering, Average latency that is seen by the user to refresh timeline.
  - *3.* Efficient timeline generation system
    - *Solution:* fb news feed timeline generation
  - *4.* Effective tweet ranking solution?
  - *5.* Suggestion to user for Whom to follow? 
    - This feature will improve user engagement. We can suggest friends of people someone follows, Famous people for the suggestions, people having more followers. As only a few suggestions can be made at any time, use Machine Learning (ML) to shuffle and re-prioritize
  - *6.* How to show top news? 
    - Use crawler to search (news, support, financial, entertainment, etc.) use [ML â€“ supervised learning or Clustering](https://sites.google.com/site/amitinterviewpreparation/machine-learning).
